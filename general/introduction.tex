The advancement of all major natural sciences has often gone hand in hand with advances in the respective measurement techniques used to formulate and validate hypotheses through experiments. 
Being able to measure key metrics in the system of interest is vital not only in scientific research, but also the development of new technologies and products. 

The field of \emph{machine learning}, especially \emph{deep learning} has seen an explosive growth over the past two decades and has become a major research focus for many in the discipline of data and computer science. 
With storage capacity and processing speed of computer hardware, such as specialized \textbf{G}raphics and \textbf{T}ensor \textbf{P}rocessing \textbf{U}nits (GPUs/ TPUs) experiencing similar advancements, the times are long gone when using neural networks to solve a problem was almost always unreasonable because of its large demand for data and computational resources. 

It is no wonder, then, that we ask how we can apply the power of machine learning to the field of measurement science. In fact, this question was asked even before the 2000s \cite{alippiArtificialIntelligenceInstruments1998}, at time when access to computing power was much more limited. Since then, with deep learning improving what can be done by neural networks, such techniques have been and will continue to be successfully used to improve measurement techniques by helping develop better sensors \cite{ballardMachineLearningComputationenabled2021}, processing raw sensor data or deriving meaning from already processed data. 

One way in which machine learning (in this case neural networks) can be used to improve the measuring process is by automating tasks that are difficult to solve through classical algorithms, but which are easy for a human to do. This is no surprise, since the idea of artificial neural networks in the first place is inspired by their biological counterpart. These problems often are very intuitively solved by the brain for a single instance, but require a large amount of effort when scaled. 
It is this aspect of machine learning that we hope to employ in our research, where we try to use neural networks to automate the process of measuring droplet size in a vapour produced by a \textbf{S}urface \textbf{A}coustic \textbf{W}aves (SAW). 

Surface Acoustic Waves can be produced by using electrodes to induce surface vibrations in piezoelectric substrates. These SAW chips have several useful applications, one of them being using them to vaporize fluids into very small droplets, which could be beneficial in fields such as e.g. medicine, for producing fine vapour of solutions of certain drugs to ensure optimal absorption in the body.
While researching and developing this technology it is important to obtain insight about the characteristics of the produced vapour, primarily droplet size and distribution. While there are already techniques to measure the size of droplets in a vapour, they all come with certain caveats. A simple solution is then, to take high speed image data of the vapour and measure the droplet size directly on the images, which is easy for one image, but constitutes an arduous task for each measurement run if one desires to obtain any statistically robust data.

The goal of this thesis is to explore the use of neural networks to automatically identify droplets in image data taken of SAW vaporized fluids and measure them with sufficient precision, as well as to compare this approach to using classical algorithms for image segmentation. Finally, a simple application will be developed with the purpose to find use in current research.